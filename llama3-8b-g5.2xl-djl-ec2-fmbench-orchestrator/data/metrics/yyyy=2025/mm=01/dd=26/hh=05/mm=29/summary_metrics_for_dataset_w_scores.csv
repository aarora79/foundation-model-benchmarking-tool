experiment_name,payload_file,instance_type,instance_count,concurrency,error_rate,prompt_token_count_mean,prompt_token_throughput,completion_token_count_mean,completion_token_throughput,latency_p50,latency_p95,latency_p99,transactions_per_minute,price_per_txn,price_per_token,score_dict,score,any_criterion_failed,error_rate_criterion_failed,latency_criterion_failed,cost_per_txn_criterion_failed,error_rate_text,latency_p95_text,price_per_10k_txn_text
llama3-8b-instruct,payload_en_3000-3840.jsonl,g5.2xlarge,1.0,1,0.0,3424,5876,16,21,0.66,0.66,0.66,102,0.0001980392156862745,0.00000006,"{'score': 5.570980392156862, 'any_criterion_failed': False, 'error_rate_criterion_failed': False, 'latency_criterion_failed': False, 'cost_per_txn_criterion_failed': False, 'error_rate_text': ""<span style='color:green'>0.00</span>"", 'latency_p95_text': ""<span style='color:green'>0.66</span>"", 'price_per_10k_txn_text': ""<span style='color:green'>1.98</span>""}",5.570980392156862,False,False,False,False,<span style='color:green'>0.00</span>,<span style='color:green'>0.66</span>,<span style='color:green'>1.98</span>
