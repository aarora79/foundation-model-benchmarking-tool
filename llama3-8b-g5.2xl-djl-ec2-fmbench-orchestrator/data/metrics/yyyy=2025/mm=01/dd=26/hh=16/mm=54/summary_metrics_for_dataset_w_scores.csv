experiment_name,payload_file,instance_type,instance_count,concurrency,error_rate,prompt_token_count_mean,prompt_token_throughput,completion_token_count_mean,completion_token_throughput,latency_p50,latency_p95,latency_p99,transactions_per_minute,price_per_txn,price_per_token,score_dict,score,any_criterion_failed,error_rate_criterion_failed,latency_criterion_failed,cost_per_txn_criterion_failed,error_rate_text,latency_p95_text,price_per_10k_txn_text
llama3-8b-instruct,payload_en_3000-3840.jsonl,g5.2xlarge,1.0,2,0.0,3424,6360,17,27,1.0,1.14,1.16,110,0.00018363636363636363,0.00000005,"{'score': 6.338181818181818, 'any_criterion_failed': False, 'error_rate_criterion_failed': False, 'latency_criterion_failed': False, 'cost_per_txn_criterion_failed': False, 'error_rate_text': ""<span style='color:green'>0.00</span>"", 'latency_p95_text': ""<span style='color:green'>1.14</span>"", 'price_per_10k_txn_text': ""<span style='color:green'>1.84</span>""}",6.338181818181818,False,False,False,False,<span style='color:green'>0.00</span>,<span style='color:green'>1.14</span>,<span style='color:green'>1.84</span>
llama3-8b-instruct,payload_en_3000-3840.jsonl,g5.2xlarge,1.0,1,0.0,3424,5702,17,22,0.7,0.7,0.7,99,0.00020404040404040403,0.00000006,"{'score': 5.547979797979798, 'any_criterion_failed': False, 'error_rate_criterion_failed': False, 'latency_criterion_failed': False, 'cost_per_txn_criterion_failed': False, 'error_rate_text': ""<span style='color:green'>0.00</span>"", 'latency_p95_text': ""<span style='color:green'>0.70</span>"", 'price_per_10k_txn_text': ""<span style='color:green'>2.04</span>""}",5.547979797979798,False,False,False,False,<span style='color:green'>0.00</span>,<span style='color:green'>0.70</span>,<span style='color:green'>2.04</span>
