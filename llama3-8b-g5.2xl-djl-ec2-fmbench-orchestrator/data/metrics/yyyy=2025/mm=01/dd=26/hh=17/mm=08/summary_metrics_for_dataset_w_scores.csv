experiment_name,payload_file,instance_type,instance_count,concurrency,error_rate,prompt_token_count_mean,prompt_token_throughput,completion_token_count_mean,completion_token_throughput,latency_p50,latency_p95,latency_p99,transactions_per_minute,price_per_txn,price_per_token,score_dict,score,any_criterion_failed,error_rate_criterion_failed,latency_criterion_failed,cost_per_txn_criterion_failed,error_rate_text,latency_p95_text,price_per_10k_txn_text
llama3-8b-instruct,payload_en_3000-3840.jsonl,g5.2xlarge,1.0,1,0.0,3424,5653,18,21,0.71,0.71,0.71,98,0.00020612244897959183,0.00000006,"{'score': 5.541938775510204, 'any_criterion_failed': False, 'error_rate_criterion_failed': False, 'latency_criterion_failed': False, 'cost_per_txn_criterion_failed': False, 'error_rate_text': ""<span style='color:green'>0.00</span>"", 'latency_p95_text': ""<span style='color:green'>0.71</span>"", 'price_per_10k_txn_text': ""<span style='color:green'>2.06</span>""}",5.541938775510204,False,False,False,False,<span style='color:green'>0.00</span>,<span style='color:green'>0.71</span>,<span style='color:green'>2.06</span>
